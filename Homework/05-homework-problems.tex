\documentclass[a4paper,10pt,landscape,twocolumn]{scrartcl}

%% Settings
\newcommand\problemset{5}
\newcommand\deadline{Friday December 9th, 20:00h}
\newif\ifcomments
\commentsfalse % hide comments
%\commentstrue % show comments

% Packages
\usepackage[english]{exercises}
\usepackage{wasysym}
\usepackage{hyperref}
\hypersetup{colorlinks=true, urlcolor = blue, linkcolor = blue}

\usepackage{tikz}
\usepackage{amssymb}

\begin{document}

\homeworkproblems

{\sffamily\noindent
Your homework must be handed in \textbf{electronically via Moodle before \deadline}. This deadline is strict and late submissions are graded with a 0. At the end of the course, the lowest of your 6 weekly homework grades will be dropped. You are strongly encouraged to work together on the exercises, including the homework. However, after this discussion phase, you have to write down and submit your own individual solution. Numbers alone are never sufficient, always motivate your answers.
}

\newcommand{\ip}[2]{\langle #1, #2\rangle}
\begin{exercise}[Hadamard code (12pt)]
For two $k$-bit strings $x$ and $y$, the inner product is defined as
\[
\ip{x}{y} := \sum_{i=1}^k x_i\cdot y_i \ \ \ \ \ \ \ \ \mod 2.
\]
Note that the inner product of two strings is a single bit. The $k$-bit Hadamard code is defined such that the codeword of $x$ is the concatenation of all possible inner products with $x$, i.e.
\[
\mathtt{enc}(x) := \left(\ip{x}{y}\right)_{y \in \{0,1\}^k}.
\]
Here, the $y$ are ordered \href{https://en.wikipedia.org/wiki/Lexicographical_order}{lexicographically}.
	\begin{subex}[(1pt)]
	Find the codewords for 010 and 1101 using the 3-bit and 4-bit Hadamard codes respectively.
	\end{subex}
	\begin{subex}[(2pt)]
	Give the explicit generator matrix $G^T$ for $k = 3$. Describe how to construct the generator matrix for arbitrary $k$.
	\end{subex}
	\begin{subex}[(2pt)]
	For a fixed non-zero $x \in \{0,1\}^k$, what is the probability that a uniformly random $y \in \{0,1\}^k$ is such that $\ip{x}{y} = 1$?
	\end{subex}
	\begin{subex}[(1pt)]
	Use (c) to find the minimal distance of the $k$-bit Hadamard code.
	\end{subex}
There is some unnecessary redundancy in the Hadamard code. For example, the first bit of $\mathtt{enc}(x)$ is always 0, regardless of what $x$ is. The \emph{punctured} $k$-bit Hadamard code attempts to solve this. It considers only the inner products with strings $y$ such that $y_1 = 1$:
\[
\mathtt{enc}'(x) := \left(\ip{x}{y}\right)_{y \in \{1\} \times \{0,1\}^{k-1}}
\]
	\begin{subex}[(3pt)]
	Find the minimal distance of the punctured $k$-bit Hadamard code using a similar approach as in (c) and (d).
	\end{subex}
	\begin{subex}[(2pt)]
	Compute the rates of the $k$-bit Hadamard code and the punctured $k$-bit Hadamard code as a function of $k$. Which is better?
	\end{subex}
	\begin{subex}[(1pt)]
	What goes wrong if we try to puncture this code again? The doubly punctured $k$-bit Hadamard code is defined by
	\[
	\mathtt{enc}''(x) := \left(\ip{x}{y}\right)_{y \in \{1\} \times \{1\} \times \{0,1\}^{k-2}}
	\]
	\end{subex}
\end{exercise}

\begin{exercise}[Shannon capacity of the complete graph (6pt)]
A graph $G$ with $n$ vertices $V(G) = \{1,2,...,n\}$ is called complete if it has edges between any two vertices, i.e. $\forall i \neq j \ : \ (i,j) \in E(G)$.
	\begin{subex}[(2pt)]
	Compute $\alpha(K_n)$, the independence number of the complete graph of size $n$.
	\end{subex}
	\begin{subex}[(2pt)]
	Show that $K_n \boxtimes K_n = K_{n^2}$.
	\\\textbf{Hint:} the \LaTeX{} command for $\boxtimes$ is \texttt{$\backslash$boxtimes} (in the \texttt{amssymb} package). See also \href{http://detexify.kirelabs.org/classify.html}{Detexify}.
	\end{subex}
	\begin{subex}[(2pt)]
	Use (a) and (b) to prove that the Shannon capacity of $K_n$ is 0. Note that this result formally confirms the intuition that channels whose confusability graphs are complete are useless for zero-error communication, because all symbols can possibly be confused with each other.
	\end{subex}
\end{exercise}

\begin{exercise}[Disjoint graphs (5 + 2 pt)]
For two graphs $G$ and $H$, the graph $G + H$ is defined as the disjoint union of the two graphs. Formally, assuming without loss of generality that $V(G) \cap V(H) = \emptyset$, then $V(G + H) = V(G) \cup V(H)$ and $E(G+H) = E(G) \cup E(H)$. (You can think of $G + H$ as $G$ and $H$ ``next to each other''.)
	\begin{subex}[(2pt)]
	Prove that $\alpha(G+H) = \alpha(G) + \alpha(H)$.
	\end{subex}
	\begin{subex**}[(2 bonus points)]
	Prove that for any three graphs $G,H,L$, it holds that
	\[
	(G+H) \boxtimes L = (G \boxtimes L) + (H \boxtimes L)
	\]
	and for the same reason, it also holds that
	\[
	G \boxtimes (H + L) = (G \boxtimes H) + (G \boxtimes L).
	\]
	\end{subex**}
	\begin{subex}[(3pt)]
	Use $\bigstar$ to derive that for any natural number $k \in \mathbb{N}$, $(G + G)^{\boxtimes k} = (G^{\boxtimes k})^{+2^k}$.
	\end{subex}
\end{exercise}

\begin{exercise}[Same-parity channel (6pt)]
Let $\mathcal{X} = \mathcal{Y} = \{1,2,3,4,5,6\}$. In this exercise, you will compute the zero-error Shannon capacity of the noisy channel with transition probabilities $P_{Y|X}(y|x) = 1/3$ if and only if $x$ and $y$ have the same parity (i.e. $x \equiv y \mod 2$).
	\begin{subex}[(2pt)]
	Give the confusability graph $G$ of the noisy channel $P_{Y|X}$ described above.
	\end{subex}
	\begin{subex}[(4pt)]
	Compute the Shannon capacity of $G$.
	\\\textbf{Hint:} use several results from the previous two exercises.
	\end{subex}
\end{exercise}







\end{document}